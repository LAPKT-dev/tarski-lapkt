{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tarski.evaluators\n",
    "from tarski.theories import Theory\n",
    "from tarski.io import PDDLReader\n",
    "from tarski.syntax import *\n",
    "from tarski.io import PDDLReader\n",
    "\n",
    "reader = PDDLReader(raise_on_error=True)\n",
    "reader.parse_domain('./benchmarks/probBLOCKS-domain.pddl')\n",
    "problem = reader.parse_instance('./benchmarks/probBLOCKS-4-2.pddl')\n",
    "lang = problem.language\n",
    "objects = list(lang.constants())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Excursion: Indexing Logical Elements\n",
    "\n",
    "It is handy to have the objects indexed in a table for easy retrieval. We can have such a table\n",
    "by name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obj_table1 = { str(obj): obj for obj in objects.domain()}\n",
    "obj_table1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, we can use the constants themselves as keys in a dictionary, by wrapping them with\n",
    "an adapter in this way"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obj_table2 = { symref(obj): [] for obj in objects.domain()}\n",
    "obj_table2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wrapping constant, terms and atoms is necessary as `Tarski` overloads most of the standard Python \n",
    "operators to provide compact syntax for formulas and expressions. For instance, if we wanted\n",
    "to compare whether two constants are the same _value_ one could try the following"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = lang.get('a')\n",
    "y = lang.get('b')\n",
    "x == y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yet using the comparison operator `==` results in the _atom_ `=(a,b)`, as `a` and `b` stand for\n",
    "two elements of a first-order language. If we use the wrappers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = lang.get('a')\n",
    "y = lang.get('b')\n",
    "symref(x) == symref(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we get to compare the actual _physical_ objects than the _logical elements_ (e.g.\n",
    " constants, arithmetic expressions, Boolean formulas) they represent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grounding    \n",
    "\n",
    "`Tarski` supports two different strategies for grounding lifted representations of STRIPS and ADL. One is based around\n",
    "the idea by Malte Helmert of constructing a logic program and computing its models so as to determine the reachability\n",
    "of a ground atom _online_. This is strategy constrasts with the classical approach, which we refer to as `naive`, where \n",
    "all potential groundings are first enumerated and then tested by reachability. While Helmert's approach is slower\n",
    "for smaller problems, it does pay off greatly for instances with thousands of ground actions, or more, which can only\n",
    "rarely be processed even by optimized implementations of the `naive` approach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To implement Helmert's algorithm, or `lp` from now on, we rely on the excellent tools developed by for Answer Set\n",
    "Programming, and inparticular, `gringo`, the suite of grounding tools for\n",
    "disjunctivel logic programs. Stable versions of tools are neatly packaged in Ubuntu 18.04 so you can install them\n",
    "like this\n",
    "\n",
    "```\n",
    "$ sudo apt install gringo\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get hold of the classes encapsulating the grounding process from the `tarski.grounding` module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tarski.grounding import LPGroundingStrategy\n",
    "from tarski.grounding.errors import ReachabilityLPUnsolvable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and ground the instance of Blocks World with a one-liner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    grounding = LPGroundingStrategy(reader.problem)\n",
    "except ReachabilityLPUnsolvable:\n",
    "    print(\"Problem was determined to be unsolvable during grounding\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the `lp` grounder can determine if an instance is unsolvable, so we need to handle that possible exception.\n",
    "\n",
    "We can inspect the results of the grounding process with ease. For the ground actions, \n",
    "we can query the `grounding` object for a dictionary that maps every action schema to\n",
    "a list tuples of object names that schema variables are to be bound to, as they were \n",
    "found to be reachable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actions = grounding.ground_actions()\n",
    "\n",
    "for name, bindings in actions.items():\n",
    "    print('Action schema', name, 'got', len(bindings), 'bindings')\n",
    "    for b in bindings:\n",
    "        print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The astute reader may be now wondering why we only return the _bindings_ rather\n",
    "than the grounded actions themselves. The reason is that doing so is not safe\n",
    "in general, as big instances (such as those commonly found on the IPC-18 benchmarks)\n",
    "result in thousands of ground operators, and is possible to exhaust the memory\n",
    "available to the Python interpreter. \n",
    "\n",
    "To ameliorate that issue, we settle for returning instead the minimal amount of data\n",
    "necessary so users can decide how to instantiate ground operators efficiently.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To access the ground atoms, or _state variables_, identified during the grounding\n",
    "process, we use a similar interface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lpvariables = grounding.ground_state_variables()\n",
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    print('p_{}:'.format(atom_index), atoms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We note that in this case we _do_ return the actual grounded language element. This\n",
    "is because the number of fluents is not generally subject to the same kind of \n",
    "combinatorial explosion that ground actions are. **This assessment may change\n",
    "in the future**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The $K_0$ compilation\n",
    "\n",
    "For the purpose of this tutorial we will look at the seminal paper by Palacios and Geffner\n",
    "\"Compiling Uncertainty Away in Conformant Planning Problems with Bounded Width\", and see how\n",
    "we can implement the $K_0$ compilation of conformant into classical problems.\n",
    "\n",
    "*Definition* (Translation $K_0$). For a conformant planning problem $P=\\langle F,I,O,G\\rangle$, the \n",
    "translation $K_0(P) = \\langle F', I', O', G'\\rangle$ is classical planning problem with\n",
    " - $F' = \\{ KL, K\\neg L\\, \\mid\\, L \\in F \\}$\n",
    " - $I' = \\{ KL \\, \\mid \\, L \\text{ is a unit clause in } I\\}$\n",
    " - $G' = \\{ KL \\, \\mid \\, L \\in G\\}$\n",
    " - $O' = O$ but with each precondition $L$ for $a \\in O$ replaced by $KL$, and each conditional effect \n",
    " $a: C \\rightarrow L$ replaced by $a: KC \\rightarrow KL$ and $a: \\neg K \\neg C \\rightarrow \\neg K \\neg L$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constructing the fluent set $F'$\n",
    "\n",
    "To construct the set of fluents $F'$ we need to create a fresh first-order language\n",
    "to accomodate the new symbols"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KP_lang = tarski.language(\"K0(P)\", theories=[Theory.EQUALITY])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will explore a compact encoding enabled by the modeling capabilities\n",
    "of `tarski`. We start creating a sort (type) for the literals of each of the atoms\n",
    "in the original conformant problem $P$. We call this type `P-literals`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_lits = KP_lang.sort(\"P-literals\", KP_lang.Object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Now we enumerate the atoms in $F$ and we keep matching lists `P_lits` and `reified_P_lits`\n",
    "that will facilitate later the compilation process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P_lits = []\n",
    "reified_P_lits = []\n",
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    f_atom = Atom(atoms.symbol, atoms.binding)\n",
    "    fp_lit = f_atom\n",
    "    fn_lit = neg(f_atom)\n",
    "    P_lits += [fp_lit, fn_lit]\n",
    "    reified_P_lits += [KP_lang.constant(str(fp_lit), p_lits), KP_lang.constant(str(fn_lit), p_lits)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we end up, for every pair of literals $L$, $\\neg L$, with _objects_ \"$L$\" and\n",
    "\"$\\neg l$\". To obtain $F'$ we need to add a new predicate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = KP_lang.predicate(\"K\", p_lits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from which we can easily define the $KL$, $K\\negL$, $\\neg K L$ \n",
    "and $\\neg K \\neg L$ literals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K(reified_P_lits[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg(K(reified_P_lits[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K(reified_P_lits[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg(K(reified_P_lits[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Excursion: Inspecting grounded initial states\n",
    "\n",
    "We go on a little excursion to show how we can enumerate the literals that\n",
    "are true in the initial state of a grounded STRIPS problem. First, we need\n",
    "to select what algorithm we want to use to evaluate expressions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reader.problem.init.evaluator = tarski.evaluators.simple.evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `simple` evaluator is a straightforward depth-first traversal that processes \n",
    " each of the nodes of the tree formed by the syntactic elements of the expression \n",
    " to be evaluated, returning either a expression or a value.\n",
    "\n",
    "Once the evaluator algorithm is selected, we can use the random access iterator\n",
    "to evaluate expressions as we do below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = []\n",
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    atom = Atom(atoms.symbol, atoms.binding)\n",
    "    if reader.problem.init[atom]:\n",
    "        I += [atom]\n",
    "    else:\n",
    "        I += [neg(atom)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " to obtain the list of literals true in the initial state."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for p in I:\n",
    "    print(p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constructing the initial state $I'$\n",
    "\n",
    "For the purpose of this tutorial, we will consider a quite difficult conformant\n",
    "problem, where the only information we have initially is that the robot hand is empty.\n",
    "\n",
    "In order to construct that initial state, we need to access the relevant predicate and\n",
    "object symbols "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "handempty = reader.problem.language.get('handempty')\n",
    "holding = reader.problem.language.get('holding')\n",
    "a, b, c, d = reader.problem.language.get('a', 'b', 'c', 'd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we can write directly the literals corresponding to the specification above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = [handempty(), neg(holding(a)), neg(holding(b)), neg(holding(c)), neg(holding(d))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain $I'$ by first computing the set of literals of the original conformant\n",
    "problem $P$ that are unit clauses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unit_clauses = set()\n",
    "K_I = []\n",
    "for l0 in I:\n",
    "    p_l0 = KP_lang.get(str(l0))\n",
    "    K_I += [K(p_l0)]\n",
    "    unit_clauses.add(symref(l0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the set `unit_clauses` to then determine which $\\neg K L$ and $\\neg K \\neg L$\n",
    "fluents we need to have in our initial state as well"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for atom_index, atoms in lpvariables.enumerate():\n",
    "    lp = Atom(atoms.symbol, atoms.binding)\n",
    "    p_lp = KP_lang.get(str(lp))\n",
    "    ln = neg(lp)\n",
    "    p_ln = KP_lang.get(str(ln))\n",
    "    if lp not in unit_clauses:\n",
    "        K_I += [neg(K(p_lp))]\n",
    "    if ln not in unit_clauses:\n",
    "        K_I += [neg(K(p_ln))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%    \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k_p in K_I:\n",
    "    print(k_p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constructing the goal state $G'$\n",
    "\n",
    "Constructing the goal state proceeds very much as for initial states, but \n",
    "way simpler, as we do not need to complete with the logical implications of\n",
    "literals as we do for initial states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "on, ontable = reader.problem.language.get('on', 'ontable')\n",
    "G = [clear(a), on(a, b), on(b, c), on(c, d), ontable(d)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K_G = []\n",
    "for l_G in G:\n",
    "    p_l_G = KP_lang.get(str(l_G))\n",
    "    K_G += [K(p_l_G)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constructing the action set $O'$\n",
    "\n",
    "Constructing the set of operators is a bit more involved. We start importing\n",
    "a helper function, `ground_schema`, that instantiates action schemas as per the\n",
    "given variable binding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tarski.syntax.transform.action_grounding import ground_schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the same interface discussed above, to get access to the set of bindings\n",
    "identified by the grounding procedure, and just call the helper function on the\n",
    "schemata and the bindings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "O = []\n",
    "for name, ops in actions.items():\n",
    "    print('Action schema', name, 'got', len(ops), 'ground actions')\n",
    "    schema = reader.problem.get_action(name)\n",
    "    print(list(schema.parameters.vars()))\n",
    "    for op in ops:\n",
    "        ground_action = ground_schema(schema, op)\n",
    "        O += [ground_action]\n",
    "        print(ground_action)\n",
    "        print(ground_action.precondition, ground_action.effects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the precondition and effect formulas of the operators in $O'$ requires\n",
    "1) creating copies of a ground operator, 2) substitute formulas (i.e. wherever\n",
    "it says $L$ it needs to say $KL$) and 3) create new add and del effects for the\n",
    "new operators. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "from tarski.syntax.transform.substitutions import substitute_subformula\n",
    "from tarski.fstrips import Action, AddEffect, DelEffect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start creating a dictionary where we map literals $L$ to their corresponding\n",
    "$K$-literal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subst = {}\n",
    "for p, Kp in zip(P_lits, [K(p) for p in reified_P_lits]):\n",
    "    subst[symref(p)] = Kp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "note the role played by the two lists `P_lits` and `reified_P_lits` we created\n",
    "above.\n",
    "\n",
    "We note that any effect, the construction of the $KC$ and $KL$ **formulas** \n",
    "is always the same, so we introduce a function that does the translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_K_condition_and_effect(subst, eff, K_prec):\n",
    "    KC = [K_prec]\n",
    "    if not isinstance(eff.condition, Tautology):\n",
    "        KC += [substitute_subformula(copy.deepcopy(eff.condition), subst)]\n",
    "    KC = land(*KC)\n",
    "    KL = subst[symref(eff.atom)]\n",
    "    KnL = subst[symref(neg(eff.atom))]\n",
    "    \n",
    "    return KC, KL, KnL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally put together the substitution rule for the $P$-literals, and construct\n",
    "the new set of operators as follows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K_O = []\n",
    "for op in O:\n",
    "    K_prec = substitute_subformula(copy.deepcopy(op.precondition), subst)\n",
    "    K_effs = []\n",
    "    for eff in op.effects:\n",
    "        KC, KL, KnL = make_K_condition_and_effect(subst, eff, K_prec)\n",
    "        if isinstance(eff, AddEffect):\n",
    "            K_effs += [AddEffect(KC, KL)]\n",
    "            K_effs += [DelEffect(KC, KnL)]\n",
    "        elif isinstance(eff, DelEffect):\n",
    "            K_effs += [DelEffect(KC, KL)]\n",
    "            K_effs += [AddEffect(KC, KnL)]\n",
    "        else:\n",
    "            raise RuntimeError(\"Effect type not supported by compilation!\")\n",
    "    K_O += [Action(KP_lang, op.name, VariableBinding(), K_prec, K_effs)]\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}